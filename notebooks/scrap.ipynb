{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Author: Alastair Hamilton\n",
    "# Date: May/June 2018\n",
    "# Title: Model for Home-depot Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Home-depot Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Wrangling\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Misc\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint as pp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import *\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ML\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tpot import TPOTRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Set path to data\n",
    "data_path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Processing features\n",
    "proc_feat = ['search_term', 'product_title', 'product_description', 'attributes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tokenise a pandas Series\n",
    "def tokenise(s, tokeniser, tokenise_fn=False):\n",
    "    if tokenise_fn:\n",
    "        return s.apply(tokeniser.tokenize)\n",
    "    else:\n",
    "        return s.apply(tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stem(s, stemmer):\n",
    "    return s.apply(lambda x: tuple(map(stemmer.stem, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation from a pandas Series\n",
    "def rmv_punc(s):\n",
    "    return s.apply(lambda x: tuple(filter(lambda y: not y.is_punct, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "def rmv_stop(s, stops):\n",
    "    return s.apply(lambda x: tuple(filter(lambda y: y not in stops, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apply function on rows of data frame (2 cols max)\n",
    "def func_row(df, func):\n",
    "    return df.apply(lambda row: func(row[0], row[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find number of words in one document (doc1) that are in another document (doc2)\n",
    "def common_words(l1, l2):\n",
    "    return sum(int(word in l1) for word in l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "- Importing attributes.csv.zip...\n",
      "- Importing train.csv.zip...\n",
      "- Importing sample_submission.csv.zip...\n",
      "- Importing test.csv.zip...\n",
      "- Importing product_descriptions.csv.zip...\n"
     ]
    }
   ],
   "source": [
    "print('Importing data...')\n",
    "\n",
    "# # Get all zipped files in data path\n",
    "zips = [f for f in os.listdir(data_path) if re.search(\".zip$\", f)]\n",
    "\n",
    "# # Unzip all files and put into dictionary, keyed by file stem\n",
    "data_dict = {}\n",
    "for zipped in zips:\n",
    "    print('- Importing {}...'.format(zipped))\n",
    "    data_dict[zipped.split('.')[0]] = pd.read_csv(data_path+zipped, compression='zip', encoding='ISO-8859-1')\n",
    "\n",
    "# # Set dataframe to piece in data dictionary\n",
    "train_df = data_dict['train']\n",
    "test_df = data_dict['test']\n",
    "prod_desc = data_dict['product_descriptions']\n",
    "attributes = data_dict['attributes']\n",
    "\n",
    "# # Clean up\n",
    "del data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "- Handling attributes data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing data...\")\n",
    "\n",
    "# # Process attributes data\n",
    "print(\"- Handling attributes data...\")\n",
    "\n",
    "# # # Deal with N/As in attributes data (drop empty records and fill in name and values with empty string)\n",
    "attr = attributes.dropna(how='all')\n",
    "attr[['name','value']] = attr[['name','value']].fillna('')\n",
    "\n",
    "# # # Ensure UID is int\n",
    "attr['product_uid'] = attr['product_uid'].apply(lambda x: int(x))\n",
    "\n",
    "# # # If \"bullet\" in attribute name then asserting name is meaningless - make an empty string\n",
    "attr['name'] = attr['name'].apply(lambda x: '' if \"Bullet\" in x else x)\n",
    "\n",
    "# # # Group name and value in attributes into single column, separated by a tab and ending in newline (for grouping stage next)\n",
    "attr['attributes'] = attr['name'] + '\\t' + attr['value'] + '\\n'\n",
    "\n",
    "# # # Drop name and values, groupby UID and sum grouped values, reset index...\n",
    "# # # ...(ie. all attributes in single cell now, separated by newlines as set up above)\n",
    "attr = attr.drop(['name','value'], axis=1).groupby('product_uid').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Creating master data frame...\n"
     ]
    }
   ],
   "source": [
    "# # Create master data frame\n",
    "print(\"- Creating master data frame...\")\n",
    "\n",
    "# # # Append train and test data\n",
    "data = train_df.append(test_df, sort=False)\n",
    "\n",
    "# # # Merge all data into one master dataframe by merging descriptions and attributes onto training data on UID...\n",
    "# # # ...Fill any NAs with empty string\n",
    "data = pd.merge(data, prod_desc, how='left', on='product_uid')\n",
    "data = data.drop('id', axis=1).merge(attr, on='product_uid', how='left').fillna('')\n",
    "\n",
    "# # # Finally create a master index column, which will be used to reference individual search terms\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>\\tVersatile connector for various 90Â° connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>\\tVersatile connector for various 90Â° connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "      <td>Application Method\\tBrush,Roller,Spray\\nAssemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "      <td>Bath Faucet Type\\tCombo Tub and Shower\\nBuilt-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "      <td>Bath Faucet Type\\tCombo Tub and Shower\\nBuilt-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                      product_title  \\\n",
       "0       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "\n",
       "          search_term relevance  \\\n",
       "0       angle bracket         3   \n",
       "1           l bracket       2.5   \n",
       "2           deck over         3   \n",
       "3    rain shower head      2.33   \n",
       "4  shower only faucet      2.67   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Not only do angles make joints stronger, they ...   \n",
       "1  Not only do angles make joints stronger, they ...   \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...   \n",
       "3  Update your bathroom with the Delta Vero Singl...   \n",
       "4  Update your bathroom with the Delta Vero Singl...   \n",
       "\n",
       "                                          attributes  \n",
       "0  \\tVersatile connector for various 90Â° connect...  \n",
       "1  \\tVersatile connector for various 90Â° connect...  \n",
       "2  Application Method\\tBrush,Roller,Spray\\nAssemb...  \n",
       "3  Bath Faucet Type\\tCombo Tub and Shower\\nBuilt-...  \n",
       "4  Bath Faucet Type\\tCombo Tub and Shower\\nBuilt-...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Clean up\n",
    "del train_df, test_df\n",
    "del prod_desc\n",
    "del attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pre-processing\n",
    "\n",
    "data has ```74067``` rows.\n",
    "- Whole pipeline takes ~16s/column (pipeline column which isn't as rich as some of the others) [9/5/19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_cols = ['product_title', 'search_term', 'product_description', 'product_description', 'attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_proc = data.loc[:, text_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Tokenisation\n",
    "Using the regexp tokeniser in NLTK with ```r'\\w+'``` was significantly faster and got rid of punctuation, which was intended.\n",
    "\n",
    "- Need to add it to ignore the weird a^ character\n",
    "\n",
    "|Tokeniser|Time taken/200 cells in product title (ms)|\n",
    "|---|---|\n",
    "|Regexp|1.28|\n",
    "|wordpunct|1.57|\n",
    "|wordtokenise|48.5|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenise_anon = lambda x: tokenise(x, RegexpTokenizer(r'\\w+'), tokenise_fn=True)\n",
    "data_proc = data_proc.apply(tokenise_anon, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Remove Stop Words\n",
    "Caching the stop words corpus was ridiculously faster (ie loading ```stopwords.words('english')``` once).\n",
    "\n",
    "|Remover|Time taken/200 cells in product title (ms)|\n",
    "|---|---|\n",
    "|nltk stop corpus filter (no cache)|435|\n",
    "|nltk stop corpus filter (cache)|6.71|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stopwords_anon = lambda x: rmv_stop(x, stopwords.words('english'))\n",
    "# data_proc = data_proc.apply(stopwords_anon, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Stemming\n",
    "Worth seeing if this affects the model further down the line. \n",
    "- Choosing snowball as faster and seen it be used for this problem before [9/5/19]\n",
    "\n",
    "|Stemmer|Time taken/200 cells in product title (ms)|\n",
    "|---|---|\n",
    "|Porter|45|\n",
    "|Snowball|37.9|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stemming_anon = lambda x: [stemmer.stem(word) for word in x]\n",
    "data_proc = data_proc.applymap(stemming_anon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_title          0\n",
       "search_term            0\n",
       "product_description    0\n",
       "product_description    0\n",
       "attributes             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_proc.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_proc['product_uid'] = data['product_uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_proc['relevance'] = data['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[simpson, strong, tie, 12, gaug, angl]</td>\n",
       "      <td>[angl, bracket]</td>\n",
       "      <td>[not, onli, do, angl, make, joint, stronger, t...</td>\n",
       "      <td>[not, onli, do, angl, make, joint, stronger, t...</td>\n",
       "      <td>[versatil, connector, for, various, 90â, conne...</td>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[simpson, strong, tie, 12, gaug, angl]</td>\n",
       "      <td>[l, bracket]</td>\n",
       "      <td>[not, onli, do, angl, make, joint, stronger, t...</td>\n",
       "      <td>[not, onli, do, angl, make, joint, stronger, t...</td>\n",
       "      <td>[versatil, connector, for, various, 90â, conne...</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            product_title      search_term  \\\n",
       "0  [simpson, strong, tie, 12, gaug, angl]  [angl, bracket]   \n",
       "1  [simpson, strong, tie, 12, gaug, angl]     [l, bracket]   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  [not, onli, do, angl, make, joint, stronger, t...   \n",
       "1  [not, onli, do, angl, make, joint, stronger, t...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  [not, onli, do, angl, make, joint, stronger, t...   \n",
       "1  [not, onli, do, angl, make, joint, stronger, t...   \n",
       "\n",
       "                                          attributes  product_uid relevance  \n",
       "0  [versatil, connector, for, various, 90â, conne...       100001         3  \n",
       "1  [versatil, connector, for, various, 90â, conne...       100001       2.5  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_proc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_feat = data_proc.loc[:, ['product_uid', 'relevance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Len of query\n",
    "data_feat['q_len'] = data_proc['search_term'].apply(len).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Get common words between query and returned product title\n",
    "com_word_anon = lambda row: common_words(row['search_term'], row['product_title'])\n",
    "data_feat['com_title'] = data_proc.loc[:, ['search_term', 'product_title']].apply(com_word_anon, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Get common words between query and returned product description\n",
    "com_word_anon = lambda row: common_words(row['search_term'], row['product_description'])\n",
    "data_feat['com_desc'] = data_proc.loc[:, ['search_term', 'product_description']].apply(com_word_anon, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Get common words between query and returned attributes\n",
    "com_word_anon = lambda row: common_words(row['search_term'], row['attributes'])\n",
    "data_feat['com_attr'] = data_proc.loc[:, ['search_term', 'attributes']].apply(com_word_anon, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>q_len</th>\n",
       "      <th>com_title</th>\n",
       "      <th>com_desc</th>\n",
       "      <th>com_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid relevance  q_len  com_title  com_desc  com_attr\n",
       "0       100001         3      2          1         0         1\n",
       "1       100001       2.5      2          0         0         0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feat.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml = data_feat.drop('product_uid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_ml[~(data_ml['relevance'] == '')], data_ml[data_ml['relevance'] == ''].drop('relevance', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train[[x for x in train.columns if x != 'relevance']], train['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = lambda true, pred: np.sqrt(mean_squared_error(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49118202139283473"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "# tpot.fit(X_train, y_train)\n",
    "# print(tpot.score(X_test, y_test))\n",
    "# preds = tpot.predict(X_test)\n",
    "# scorer(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.5, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=13, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=1, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=0.8500000000000001, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49118202139283473"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mdl.fit(X,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(y_pred, index=test_df['id'], columns=['relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.061226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.061226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.204339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.617579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.327509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    relevance\n",
       "id           \n",
       "1    2.061226\n",
       "4    2.061226\n",
       "5    2.204339\n",
       "6    2.617579\n",
       "7    2.327509"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homedepot",
   "language": "python",
   "name": "homedepot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "10",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 292.98578000000003,
   "position": {
    "height": "315.191px",
    "left": "837.222px",
    "right": "20px",
    "top": "120px",
    "width": "342.778px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
