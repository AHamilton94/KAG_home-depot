{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Feature Analysis and ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas error display OFF\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Data Path\n",
    "data_path = \"../data/\"\n",
    "\n",
    "# Image Path\n",
    "img_path = \"./plots/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Features\n",
    "features = pd.read_csv(data_path+'features.csv').drop(['Unnamed: 0','product_uid'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ratio features using query length\n",
    "features['title_ratio'] = features['com_title'] / features['q_len']\n",
    "features['desc_ratio'] = features['com_desc'] / features['q_len']\n",
    "features['attr_ratio'] = features['com_attr'] / features['q_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each ratio, create a linear regression plot against relevance\n",
    "for x in ['title_ratio', 'desc_ratio', 'attr_ratio']:\n",
    "    bit = x.split('_')[0].title()\n",
    "    ax = sns.lmplot(x='relevance', y=x, data=features, scatter_kws={'alpha':0.01})\n",
    "    plt.title('Scatter Plot of Relevance Scores\\nAgainst Ratio of Common Words in Query and {}'.format(bit))\n",
    "    plt.xlabel('Relevance Scores')\n",
    "    plt.ylabel('Query/{} Ratio'.format(bit))\n",
    "    plt.savefig(img_path+'{}_ratio.png'.format(bit), dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose features\n",
    "df = features.drop(['title_ratio', 'desc_ratio', 'attr_ratio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('relevance',axis=1),\n",
    "                                                    df['relevance'],\n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Tree Model\n",
    "gbr = GradientBoostingRegressor(n_estimators=150, learning_rate=0.4, loss='huber', alpha=0.9)\n",
    "\n",
    "# Random forest Model\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Model\n",
    "mdl = rf\n",
    "model_name = 'Random_Forest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show variable importance\n",
    "importances = pd.np.nan\n",
    "if mdl is gbr or mdl is rf:\n",
    "    importances = pd.Series(data=mdl.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "if importances is not pd.np.nan:\n",
    "    ax = importances.plot(kind='bar')\n",
    "    plt.title('Bar Plot of Relative Importance of Features using the {} Model'.format(model_name))\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Relative Importance')\n",
    "    plt.savefig(img_path+'{}_relimp.png'.format(model_name), dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions...\n",
    "pred = mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "print('MSE: {:.4f}\\nMAE: {:.4f}\\nR2: {:.4f}'.format(mean_squared_error(y_test, pred), mean_absolute_error(y_test, pred), r2_score(y_test, pred), mdl.score(X_test, y_test)))\n",
    "print('\\nCross Validation')\n",
    "print(cross_val_score(mdl, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals\n",
    "s = np.std(pred)\n",
    "std_resids = (pred - y_test.values)/s\n",
    "df = pd.DataFrame({\"std_resids\":std_resids, \"preds\":pred})\n",
    "# df['Range'] = df['std_resids'].apply(lambda x: 'Within 2 stdevs' if (x>2.0 or x<-2.0) else 'Outwith 2 stdevs')\n",
    "df['Range'] = df['std_resids'].apply(lambda x: 'r' if (x>2.0 or x<-2.0) else 'b')\n",
    "ax = df.plot(kind='scatter', x='preds', y='std_resids', alpha=0.01, c=df['Range'].values)\n",
    "plt.title('Scatter Plot of Residuals (in units of standard deviations)\\nResidual Outwith 2 Stdev. has been Coloured Red')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual/Standard Deviation')\n",
    "print('Proportion of residuals outwith 2 standard deviations: {}'.format(df['Range'].value_counts()['b']/len(df)))\n",
    "plt.savefig(img_path+'{}_std_resids.png'.format(model_name), dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deviance for GBT - testing for over-fitting\n",
    "if mdl is gbr:\n",
    "    test_score = np.zeros((150,), dtype=np.float64)\n",
    "\n",
    "    for i, y_pred in enumerate(mdl.staged_predict(X_test)):\n",
    "        test_score[i] = mdl.loss_(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Deviance')\n",
    "    plt.plot(np.arange(150) + 1, mdl.train_score_, 'b-',\n",
    "             label='Training Set Deviance')\n",
    "    plt.plot(np.arange(150) + 1, test_score, 'r-',\n",
    "             label='Test Set Deviance')\n",
    "    plt.title('Line Plot of Deviance of Test and Train Predictions\\nAgainst Boosting Iterations when using Gradient Boosted Tree')\n",
    "    plt.xlabel('Boosting Iterations')\n",
    "    plt.ylabel('Deviance')\n",
    "    plt.savefig(img_path+'gbr_dev.png', dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home-depot",
   "language": "python",
   "name": "home-depot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
